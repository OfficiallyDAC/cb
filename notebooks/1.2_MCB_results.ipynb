{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook merges the results for the left and right hemisphere, notebooks `1.2_MCB_with_bootstrap_left.ipynb` and `1.2_MCB_with_bootstrap_right.ipynb` respectively, and saves the MCBs made of statistically significant edges at $10\\%$ level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"..\\code\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import load_obj, save_obj\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"../data/\"\n",
    "ts_dir=\"../data/TimeSeriesAAL/\" \n",
    "processed=\"../data/processed/\"\n",
    "diffreg=\"../data/processed/diff_regions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace=False\n",
    "verbose=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results from left and right hemis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "results_left=load_obj('1.2_bootstrap_ms_results_cut_idiosyncratic_left_0.2', processed)\n",
    "results_right=load_obj('1.2_bootstrap_ms_results_cut_idiosyncratic_right_0.2', processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if replace:\n",
    "    results = results_left.copy()\n",
    "    for sample in list(results['multiscale'].keys()):\n",
    "        results['multiscale'][sample]['right']=results_right['multiscale'][sample]['right'].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "J=5\n",
    "hemis=['left','right']\n",
    "nsamples=100\n",
    "alpha=10\n",
    "percentiles = jnp.array([alpha//2,50,100-alpha//2], dtype=jnp.int16)\n",
    "\n",
    "if replace:\n",
    "    results['bootstrap results']=dict()\n",
    "\n",
    "    for hemi in hemis:\n",
    "        results['bootstrap results'][hemi]=dict()\n",
    "        for scale in range(J):\n",
    "            results['bootstrap results'][hemi]['scale {}'.format(J-scale)]=dict()\n",
    "            for sample in range(nsamples):\n",
    "                itema = results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Solution']\n",
    "                itemc = results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Causal tensor']\n",
    "                if sample==0:\n",
    "                    A_tilde=deepcopy(itema)\n",
    "                    C_tilde=deepcopy(itemc)\n",
    "                else:\n",
    "                    A_tilde=jnp.concatenate((A_tilde,itema),axis=0)\n",
    "                    C_tilde=jnp.concatenate((C_tilde,itemc),axis=0)\n",
    "\n",
    "            C_tilde_l, C_median, C_tilde_u=jnp.percentile(C_tilde, percentiles, axis=0) #(K,K)\n",
    "            C_bar = C_tilde_l*C_tilde_u\n",
    "            A_b = jnp.where(C_bar>0,1,0)\n",
    "            C_b = A_b*C_median\n",
    "\n",
    "            results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Concatenated samples solutions']=A_tilde\n",
    "            results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Concatenated samples causal tensors']=C_tilde\n",
    "            results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Solution']=A_b\n",
    "            results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Causal tensor']=C_b\n",
    "\n",
    "    save_obj(results, '1.2_results_bootstrap_ms_cut_idiosyncratic_0.2', processed)\n",
    "\n",
    "else:\n",
    "    results=load_obj('1.2_results_bootstrap_ms_cut_idiosyncratic_0.2', processed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = load_obj('region_names', processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 41, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 26, 25, 24, 23, 22,\n",
       "       21, 20, 19, 17, 14, 13, 11, 10,  9,  8,  1], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups=np.array([1,7,15,17,19,21,23,25,27,29,31,33,37,39,41,43,45,47,49,51,55,61,63,67,69,71,73, 87])\n",
    "splitting_correct=(89*np.ones_like(groups)-groups)//2 #divide by 2 to account for left and right hemi\n",
    "splitting_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of connections 88, final number of connections 9\n",
      "Initial number of connections 96, final number of connections 10\n",
      "Initial number of connections 96, final number of connections 15\n",
      "Initial number of connections 89, final number of connections 17\n",
      "Initial number of connections 73, final number of connections 22\n",
      "Initial number of connections 76, final number of connections 26\n",
      "Initial number of connections 70, final number of connections 25\n",
      "Initial number of connections 59, final number of connections 26\n",
      "Initial number of connections 46, final number of connections 14\n",
      "Initial number of connections 46, final number of connections 18\n"
     ]
    }
   ],
   "source": [
    "if replace: writer = pd.ExcelWriter('1.2_Summary_statistics_bootstrap_results_multiscale.xlsx')\n",
    "\n",
    "#preserved connections\n",
    "lb=5\n",
    "ub=95\n",
    "hemis = ['right', 'left']\n",
    "\n",
    "for scale in range(J):\n",
    "    for hemi in hemis: \n",
    "\n",
    "        initial_ = results['multiscale'][0][hemi]['scale {}'.format(J-scale)]['Initial universe'] #this is equal for all bootstrap samples\n",
    "        final_ = 2*results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Solution'] #this way, when I sum, I obtain -1 and +1\n",
    "        weights_ = results['bootstrap results'][hemi]['scale {}'.format(J-scale)]['Concatenated samples causal tensors']\n",
    "        inn=len(jnp.flatnonzero(initial_))\n",
    "        fnn=len(jnp.flatnonzero(final_))\n",
    "\n",
    "        print(\"Initial number of connections {}, final number of connections {}\".format(inn, fnn))\n",
    "        inout_=initial_+final_\n",
    "        inout_nnz=inout_.nonzero()\n",
    "\n",
    "        inout_df = pd.DataFrame(index=np.arange(inn), columns=['source', 'target', 'in/out', 'median', 'min', 'max', '{}%'.format(lb), '25%', '75%', '{}%'.format(ub)])\n",
    "\n",
    "        for i in range(len(inout_df)):\n",
    "            s=inout_nnz[0][i].item()\n",
    "            t=inout_nnz[1][i].item()\n",
    "            io=inout_[s,t].item()\n",
    "            min_ = weights_[:,s,t].min().item()\n",
    "            max_ = weights_[:,s,t].max().item()\n",
    "            median_ = jnp.percentile(weights_[:,s,t], 50).item()\n",
    "            liqr = jnp.percentile(weights_[:,s,t], 25).item()\n",
    "            uiqr = jnp.percentile(weights_[:,s,t], 75).item()\n",
    "            lbp = jnp.percentile(weights_[:,s,t], lb).item()\n",
    "            ubp = jnp.percentile(weights_[:,s,t], ub).item()\n",
    "\n",
    "            source_ = results['map_idx_to_regions'][s]['Region']\n",
    "            target_ = results['map_idx_to_regions'][t]['Region']\n",
    "\n",
    "            inout_df.iloc[i]=[source_,target_, io, median_, min_, max_, lbp, liqr, uiqr, ubp]\n",
    "\n",
    "        if replace: inout_df.to_excel(writer, sheet_name='scale {} - {} hemi'.format(J-scale, hemi), index=True)\n",
    "\n",
    "if replace:\n",
    "    writer.save()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPCG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
