{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook retrieve the multiscale causal backbone (MCB) for the left hemisphere, by also employing bootstrap with resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"..\\code\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from MCB import delta_score, vdelta_score, vloglike\n",
    "from utils import load_obj, save_obj\n",
    "from metrics import is_dag\n",
    "from copy import deepcopy\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"../data/\"\n",
    "ts_dir=\"../data/TimeSeriesAAL/\" \n",
    "processed=\"../data/processed/\"\n",
    "diffreg=\"../data/processed/diff_regions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace=False\n",
    "verbose=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Multi-Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((225, 225, 200), (225, 225, 200))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_left_exam0=load_obj('1.0_ms_left_hemi_exam0', data_dir=processed)\n",
    "ms_left_exam1=load_obj('1.0_ms_left_hemi_exam1', data_dir=processed)\n",
    "ms_right_exam0=load_obj('1.0_ms_right_hemi_exam0', data_dir=processed)\n",
    "ms_right_exam1=load_obj('1.0_ms_right_hemi_exam1', data_dir=processed)\n",
    "\n",
    "ms_left=np.concatenate((ms_left_exam0,ms_left_exam1), axis=-1)\n",
    "ms_right=np.concatenate((ms_right_exam0,ms_right_exam1), axis=-1)\n",
    "\n",
    "ms_left.shape, ms_right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 200, 45, 1184), (5, 200, 45, 1184))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_jskt_0_L = load_obj('0.0_ts_ms_0_L',processed)[1:]\n",
    "X_jskt_1_L = load_obj('0.0_ts_ms_1_L',processed)[1:]\n",
    "X_jskt_0_R = load_obj('0.0_ts_ms_0_R',processed)[1:]\n",
    "X_jskt_1_R = load_obj('0.0_ts_ms_1_R',processed)[1:]\n",
    "\n",
    "X_jskt_L=np.concatenate((X_jskt_0_L,X_jskt_1_L),axis=1)\n",
    "X_jskt_R=np.concatenate((X_jskt_0_R,X_jskt_1_R),axis=1)\n",
    "\n",
    "X_jskt_L.shape,X_jskt_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "#create reproducible 100 subkeys\n",
    "nsamples=100 #bootstrap samples\n",
    "key = random.PRNGKey(0)\n",
    "key, *_100_subkeys = random.split(key, num=nsamples+1)\n",
    "del key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "J,S,K,T=X_jskt_L.shape\n",
    "hemis=['left']\n",
    "\n",
    "if replace:    \n",
    "    results=dict()\n",
    "    results['multiscale']=dict()\n",
    "    threshold=0.2\n",
    "    parallelized=True\n",
    "    method='pinv'\n",
    "\n",
    "    #bootstrap with resampling\n",
    "    for sample in tqdm(range(nsamples)):\n",
    "        print(\"################# SAMPLE {} #################\".format(sample))\n",
    "        \n",
    "        results['multiscale'][sample]=dict()\n",
    "        #select the idx for this sample \n",
    "        bs_idx=random.randint(_100_subkeys[sample], (S,), 0, S)\n",
    "\n",
    "        #iterate over hemispheres\n",
    "        for hemi in hemis:\n",
    "            \n",
    "            results['multiscale'][sample][hemi]=dict()\n",
    "            C_sjpk=jnp.zeros((S,J,K,K))\n",
    "\n",
    "            if hemi=='left':\n",
    "                X_jskt=deepcopy(X_jskt_L[:,bs_idx]) #select the ts according to the bootstrap idx\n",
    "                C_dndns=deepcopy(ms_left[...,bs_idx]) #select the matrices according to the bootstrap idx\n",
    "\n",
    "                for s in range(S):\n",
    "                    C_sjpk = C_sjpk.at[s].set(jnp.array([C_dndns[i*K:(i+1)*K,i*K:(i+1)*K,s] for i in range(J)]))\n",
    "                C_jspk=C_sjpk.transpose((1,0,2,3))\n",
    "\n",
    "            elif hemi=='right':\n",
    "                X_jskt=deepcopy(X_jskt_R[:,bs_idx]) #same as above\n",
    "                C_dndns=deepcopy(ms_right[...,bs_idx]) #same as above\n",
    "            \n",
    "                for s in range(S):\n",
    "                    C_sjpk = C_sjpk.at[s].set(jnp.array([C_dndns[i*K:(i+1)*K,i*K:(i+1)*K,s] for i in range(J)]))\n",
    "                C_jspk=C_sjpk.transpose((1,0,2,3))\n",
    "            else:\n",
    "                print(\"Side can be either 'right' or 'left'.\")\n",
    "                break\n",
    "            \n",
    "            #this loop can be parallelized\n",
    "            for scale in tqdm(range(J)):\n",
    "                results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]=dict()\n",
    "                #load the universe\n",
    "                edges_df = pd.read_excel('1.1_multi_scale_edges.xlsx', sheet_name='Raw_scale{}'.format(J-scale), index_col=0)\n",
    "                \n",
    "                X = deepcopy(X_jskt[scale])\n",
    "                C_spk = deepcopy(C_jspk[scale])\n",
    "\n",
    "                print(\"\\n\\n######### {} hemisphere - scale {} #########\\n\".format(hemi, J-scale))\n",
    "            \n",
    "                edges_set = edges_df[edges_df['hemi']==hemi]\n",
    "\n",
    "                A = jnp.zeros((K,K), dtype=jnp.int16) #solution\n",
    "                G = jnp.zeros((K,K), dtype=jnp.float32) #universe\n",
    "\n",
    "                #cut at certain threshold\n",
    "                A_spk = jnp.sign((jnp.abs(C_spk)>threshold).astype(jnp.int16)).astype(jnp.int16)\n",
    "                G = G.at[list(edges_set['source_idx']),list(edges_set['target_idx'])].set(-1.) #initialize universe with persistent connections\n",
    "                P_spk = (A_spk+G).astype(jnp.int16) #idiosyncratic connections\n",
    "                P_spk = jnp.where(P_spk==-1.,0.,P_spk)\n",
    "\n",
    "                results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Initial universe']=G\n",
    "                results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Idiosyncratic']=P_spk\n",
    "\n",
    "                print(\"Universe initially has {} edges\\n\".format(len(jnp.flatnonzero(G))))\n",
    "\n",
    "                LLG = -jnp.inf*jnp.ones((S,K,K)) #log-likelihood given the insertion of candidate edges: needed for selecting the likelihood associated with best edge\n",
    "                LLA = [vloglike(X[:,i], X, C_spk[...,i]*P_spk[...,i]) for i in range(K)] #log-likelihood given edges in A\n",
    "\n",
    "                #needed to store changes in causal coefficients given an edge addition.\n",
    "                #so, for each subject, the entry of the matrix KxK is the vector of coefficients\n",
    "                #resulting from the addition of the edge corresponding to that entry.\n",
    "                B_augmented = jnp.zeros((S,K,K,K)) \n",
    "                B = jnp.zeros((S,K,K)) #this is the final causal coefficients tensor.\n",
    "\n",
    "                evaluate_candidate = True\n",
    "                first_step=True\n",
    "                isdag=True #dagness condition\n",
    "\n",
    "                while evaluate_candidate:\n",
    "                    \n",
    "                    evaluate_candidate=False\n",
    "                    \n",
    "                    #only update the scores if the edge has been added\n",
    "                    if isdag:\n",
    "                        if first_step:\n",
    "                            children=jnp.unique(G.nonzero()[1]) #nodes on the columns with at least 1 parent\n",
    "                            first_step=False\n",
    "                        else: \n",
    "                            children=[child_of_last_edge_added_idx]\n",
    "\n",
    "                        for child in children:\n",
    "                            \n",
    "                            child_columns=P_spk[...,child]+A[:,child]\n",
    "                            candidate_parents = G[:,child].nonzero()[0].tolist()\n",
    "                            ll0 = LLA[child]\n",
    "\n",
    "                            for candidate_parent in candidate_parents:\n",
    "                            \n",
    "                                if not parallelized:\n",
    "                                    scores_candidate = jnp.zeros(S)\n",
    "                                    lls_candidate = jnp.zeros(S)\n",
    "                                    betas_child = jnp.zeros([S,K])\n",
    "                                    \n",
    "                                    for subject in range(S):\n",
    "                                        score_candidate_item, ll_candidate_item, betas_child_item=delta_score(candidate_parent, child, child_columns[subject], X[subject], ll0[subject], method, parallelized)\n",
    "                                        \n",
    "                                        scores_candidate=scores_candidate.at[subject].set(score_candidate_item)\n",
    "                                        lls_candidate=lls_candidate.at[subject].set(ll_candidate_item)\n",
    "                                        betas_child=betas_child.at[subject].set(betas_child_item)\n",
    "                                \n",
    "                                elif parallelized:  \n",
    "                                    #this is vmapped (parallelized).\n",
    "                                    scores_candidate, lls_candidate, betas_child=vdelta_score(candidate_parent, child, child_columns, X, ll0, method, parallelized)\n",
    "\n",
    "                                score_candidate = scores_candidate.sum()\n",
    "\n",
    "                                B_augmented = B_augmented.at[...,candidate_parent,child].set(betas_child)\n",
    "                                G = G.at[candidate_parent,child].set(score_candidate)\n",
    "                                LLG = LLG.at[:,candidate_parent,child].set(lls_candidate)\n",
    "                                \n",
    "                    #take the parent with the maximum score\n",
    "                    max_score = G.max().item()\n",
    "                    idx_max = jnp.unravel_index(G.argmax(), G.shape)\n",
    "                    if max_score>0:\n",
    "                        parent_of_last_edge_added, child_of_last_edge_added=idx_max\n",
    "                        parent_of_last_edge_added_idx, child_of_last_edge_added_idx=parent_of_last_edge_added.item(), child_of_last_edge_added.item()\n",
    "                        \n",
    "                        #check aciclycity\n",
    "                        A_tilde = deepcopy(A).astype(jnp.float32)\n",
    "                        A_tilde = A_tilde.at[parent_of_last_edge_added_idx, child_of_last_edge_added_idx].set(1.)\n",
    "                        \n",
    "                        isdag = is_dag(np.asarray(A_tilde))\n",
    "\n",
    "                        if isdag:\n",
    "                            A = A.at[parent_of_last_edge_added_idx, child_of_last_edge_added_idx].set(1)\n",
    "                            B = B.at[..., child_of_last_edge_added_idx].set(B_augmented[...,parent_of_last_edge_added_idx,child_of_last_edge_added_idx])\n",
    "                            LLA[child_of_last_edge_added_idx]=LLG[:,parent_of_last_edge_added_idx, child_of_last_edge_added_idx]\n",
    "                            common_edges=(jnp.cumsum(jnp.sign(jnp.abs(B)), axis=0)[-1]==200).sum()\n",
    "                            if verbose:\n",
    "                                print(\"Added {}->{}\".format(parent_of_last_edge_added_idx,child_of_last_edge_added_idx))\n",
    "                                print(\"Number of common edges {}\".format(common_edges))\n",
    "                        else:\n",
    "                            if verbose:\n",
    "                                print(\"Not added {}->{} since it induces cicles in the solution.\".format(parent_of_last_edge_added_idx,child_of_last_edge_added_idx))\n",
    "                    \n",
    "                    #remove the evaluated edge\n",
    "                    G = G.at[(parent_of_last_edge_added_idx,child_of_last_edge_added_idx)].set(0.)\n",
    "                    #if added exclude its reverse\n",
    "                    if isdag:\n",
    "                        G = G.at[(child_of_last_edge_added_idx,parent_of_last_edge_added_idx)].set(0.)\n",
    "                    G = jnp.where(G<0., 0., G)\n",
    "\n",
    "                    if len(jnp.where(G>0.)[0])>0: \n",
    "                        evaluate_candidate=True \n",
    "\n",
    "                results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Solution']=A\n",
    "                results['multiscale'][sample][hemi]['scale {}'.format(J-scale)]['Causal tensor']=B\n",
    "                print(\"\\n Added {} edges\".format(len(jnp.flatnonzero(A))))\n",
    "\n",
    "    #names\n",
    "    names = load_obj('region_names', processed)\n",
    "    idx_left = load_obj('index_left_regions',processed)\n",
    "\n",
    "    names_left_df=names.iloc[idx_left].copy()\n",
    "    names_reidx=names_left_df.copy()\n",
    "    names_reidx.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    results['map_idx_to_regions']=names_reidx.to_dict('index').copy()\n",
    "    save_obj(results, '1.2_bootstrap_ms_results_cut_idiosyncratic_left_0.2', processed)\n",
    "\n",
    "else:\n",
    "    results=load_obj('1.2_bootstrap_ms_results_cut_idiosyncratic_left_0.2', processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPCG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
